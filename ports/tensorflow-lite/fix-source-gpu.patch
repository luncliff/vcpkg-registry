diff --git a/tensorflow/lite/delegates/gpu/cl/cl_operation.h b/tensorflow/lite/delegates/gpu/cl/cl_operation.h
index 63748117..7ff6bb82 100644
--- a/tensorflow/lite/delegates/gpu/cl/cl_operation.h
+++ b/tensorflow/lite/delegates/gpu/cl/cl_operation.h
@@ -79,6 +79,7 @@ class ClOperation {
                            operation_->work_group_size_);
   }
 
+#if defined(cl_khr_command_buffer)
   absl::Status AddToCommanBuffer(cl_command_buffer_khr cb) {
     RETURN_IF_ERROR(cl_args_.Bind(kernel_.kernel()));
     std::array<size_t, 3> local;
@@ -98,6 +99,7 @@ class ClOperation {
     }
     return absl::OkStatus();
   }
+#endif
 
   absl::Status AddToQueue(ProfilingCommandQueue* queue, CLEvent* event) {
     RETURN_IF_ERROR(cl_args_.Bind(kernel_.kernel()));
diff --git a/tensorflow/lite/delegates/gpu/cl/inference_context.cc b/tensorflow/lite/delegates/gpu/cl/inference_context.cc
index b1dc7862..24e34114 100644
--- a/tensorflow/lite/delegates/gpu/cl/inference_context.cc
+++ b/tensorflow/lite/delegates/gpu/cl/inference_context.cc
@@ -319,12 +319,14 @@ absl::Status InferenceContext::InitFromGpuModel(
   return absl::OkStatus();
 }
 
+#if defined(cl_khr_command_buffer)
 absl::Status InferenceContext::AddToCommanBuffer(cl_command_buffer_khr cb) {
   for (auto& node : nodes_) {
     RETURN_IF_ERROR(node.cl_operation.AddToCommanBuffer(cb));
   }
   return absl::OkStatus();
 }
+#endif
 
 absl::Status InferenceContext::RestoreDeserialized(
     const absl::Span<const uint8_t> serialized_model, Environment* env,
diff --git a/tensorflow/lite/delegates/gpu/cl/inference_context.h b/tensorflow/lite/delegates/gpu/cl/inference_context.h
index e5e883b0..41a655e2 100644
--- a/tensorflow/lite/delegates/gpu/cl/inference_context.h
+++ b/tensorflow/lite/delegates/gpu/cl/inference_context.h
@@ -74,7 +74,9 @@ class InferenceContext {
       Environment* env, std::vector<uint8_t>* serialized_model = nullptr,
       Buffer* shared_buffer = nullptr);
 
+#if defined(cl_khr_command_buffer)
   absl::Status AddToCommanBuffer(cl_command_buffer_khr cb);
+#endif
 
   // Applies OpenCL-specific transformations to the graph before the
   // initialization. These transformations are either impossible or useless in
diff --git a/tensorflow/lite/delegates/gpu/cl/opencl_wrapper.cc b/tensorflow/lite/delegates/gpu/cl/opencl_wrapper.cc
index 7bf63235..d3a43129 100644
--- a/tensorflow/lite/delegates/gpu/cl/opencl_wrapper.cc
+++ b/tensorflow/lite/delegates/gpu/cl/opencl_wrapper.cc
@@ -233,6 +233,7 @@ void LoadOpenCLFunctions(void* libopencl, bool use_wrapper) {
   LoadFunction(clEnqueueAcquireEGLObjectsKHR);
   LoadFunction(clEnqueueReleaseEGLObjectsKHR);
 
+#if defined(cl_khr_command_buffer)
   // cl_khr_command_buffer extension
   LoadFunction(clCreateCommandBufferKHR);
   LoadFunction(clRetainCommandBufferKHR);
@@ -241,6 +242,7 @@ void LoadOpenCLFunctions(void* libopencl, bool use_wrapper) {
   LoadFunction(clEnqueueCommandBufferKHR);
   LoadFunction(clCommandNDRangeKernelKHR);
   LoadFunction(clGetCommandBufferInfoKHR);
+#endif
 
   LoadQcomExtensionFunctions();
 }
@@ -363,6 +365,7 @@ PFN_clCreateFromEGLImageKHR clCreateFromEGLImageKHR;
 PFN_clEnqueueAcquireEGLObjectsKHR clEnqueueAcquireEGLObjectsKHR;
 PFN_clEnqueueReleaseEGLObjectsKHR clEnqueueReleaseEGLObjectsKHR;
 
+#if defined(cl_khr_command_buffer)
 // cl_khr_command_buffer extension
 PFN_clCreateCommandBufferKHR clCreateCommandBufferKHR;
 PFN_clRetainCommandBufferKHR clRetainCommandBufferKHR;
@@ -371,6 +374,7 @@ PFN_clFinalizeCommandBufferKHR clFinalizeCommandBufferKHR;
 PFN_clEnqueueCommandBufferKHR clEnqueueCommandBufferKHR;
 PFN_clCommandNDRangeKernelKHR clCommandNDRangeKernelKHR;
 PFN_clGetCommandBufferInfoKHR clGetCommandBufferInfoKHR;
+#endif
 
 DEFINE_QCOM_FUNCTION_PTRS
 
diff --git a/tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h b/tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h
index f946e8e2..54fcc718 100644
--- a/tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h
+++ b/tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h
@@ -522,6 +522,7 @@ typedef cl_int(CL_API_CALL *PFN_clEnqueueReleaseEGLObjectsKHR)(
     const cl_mem * /*mem_objects*/, cl_uint /*num_events_in_wait_list*/,
     const cl_event * /*event_wait_list*/, cl_event * /*event*/);
 
+#if defined(cl_khr_command_buffer)
 // cl_khr_command_buffer
 typedef cl_command_buffer_khr(CL_API_CALL *PFN_clCreateCommandBufferKHR)(
     cl_uint /*num_queues*/, const cl_command_queue * /*queues*/,
@@ -559,6 +560,7 @@ typedef cl_int(CL_API_CALL *PFN_clGetCommandBufferInfoKHR)(
     cl_command_buffer_khr /*command_buffer*/,
     cl_command_buffer_info_khr /*param_name*/, size_t /*param_value_size*/,
     void * /*param_value*/, size_t * /*param_value_size_ret*/);
+#endif
 
 extern PFN_clGetPlatformIDs clGetPlatformIDs;
 extern PFN_clGetPlatformInfo clGetPlatformInfo;
@@ -678,6 +680,7 @@ extern PFN_clCreateFromEGLImageKHR clCreateFromEGLImageKHR;
 extern PFN_clEnqueueAcquireEGLObjectsKHR clEnqueueAcquireEGLObjectsKHR;
 extern PFN_clEnqueueReleaseEGLObjectsKHR clEnqueueReleaseEGLObjectsKHR;
 
+#if  defined(cl_khr_command_buffer)
 // cl_khr_command_buffer extension
 extern PFN_clCreateCommandBufferKHR clCreateCommandBufferKHR;
 extern PFN_clRetainCommandBufferKHR clRetainCommandBufferKHR;
@@ -686,6 +689,7 @@ extern PFN_clFinalizeCommandBufferKHR clFinalizeCommandBufferKHR;
 extern PFN_clEnqueueCommandBufferKHR clEnqueueCommandBufferKHR;
 extern PFN_clCommandNDRangeKernelKHR clCommandNDRangeKernelKHR;
 extern PFN_clGetCommandBufferInfoKHR clGetCommandBufferInfoKHR;
+#endif
 
 // For convenient image creation
 // It uses clCreateImage if it available (clCreateImage available since cl 1.2)
diff --git a/tensorflow/lite/delegates/gpu/cl/util.cc b/tensorflow/lite/delegates/gpu/cl/util.cc
index b615a9b6..e61432a5 100644
--- a/tensorflow/lite/delegates/gpu/cl/util.cc
+++ b/tensorflow/lite/delegates/gpu/cl/util.cc
@@ -152,12 +152,18 @@ std::string CLErrorCodeToString(cl_int error_code) {
       return "Invalid device queue";
     case CL_INVALID_GL_SHAREGROUP_REFERENCE_KHR:
       return "Invalid GL sharegroup reference KHR";
+#if defined(CL_INVALID_COMMAND_BUFFER_KHR)
     case CL_INVALID_COMMAND_BUFFER_KHR:
       return "Invalid command buffer KHR";
+#endif
+#if defined(CL_INVALID_SYNC_POINT_WAIT_LIST_KHR)
     case CL_INVALID_SYNC_POINT_WAIT_LIST_KHR:
       return "Invalid sync point wait list KHR";
+#endif
+#if defined(CL_INCOMPATIBLE_COMMAND_QUEUE_KHR)
     case CL_INCOMPATIBLE_COMMAND_QUEUE_KHR:
       return "Incompatible command queue KHR";
+#endif
 
     default:
       return absl::StrCat("Unknown OpenCL error code - ", error_code);
