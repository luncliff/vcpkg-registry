diff --git a/tensorflow/lite/delegates/gpu/api.h b/tensorflow/lite/delegates/gpu/api.h
index 4594410a..987747cd 100644
--- a/tensorflow/lite/delegates/gpu/api.h
+++ b/tensorflow/lite/delegates/gpu/api.h
@@ -230,7 +230,7 @@ bool IsValid(const TensorObjectDef& def);
 uint32_t NumElements(const TensorObjectDef& def);
 
 using TensorObject =
-    absl::variant<std::monostate, OpenGlBuffer, OpenGlTexture, CpuMemory,
+    std::variant<std::monostate, OpenGlBuffer, OpenGlTexture, CpuMemory,
                   OpenClBuffer, OpenClTexture, VulkanBuffer, VulkanTexture>;
 
 // @return true if object is set and corresponding values are defined.
diff --git a/tensorflow/lite/delegates/gpu/common/tasks/mean_stddev_normalization.cc b/tensorflow/lite/delegates/gpu/common/tasks/mean_stddev_normalization.cc
index f45a58c7..c8871346 100644
--- a/tensorflow/lite/delegates/gpu/common/tasks/mean_stddev_normalization.cc
+++ b/tensorflow/lite/delegates/gpu/common/tasks/mean_stddev_normalization.cc
@@ -43,8 +43,8 @@ absl::Status CheckIfValidNodeOfType(const Node* node,
 }
 
 absl::Status GetElementwiseScalarValue(const Node* node, float* result) {
-  auto attr = absl::any_cast<ElementwiseAttributes>(node->operation.attributes);
-  const float* value = absl::get_if<float>(&attr.param);
+  auto attr = std::any_cast<ElementwiseAttributes>(node->operation.attributes);
+  const float* value = std::get_if<float>(&attr.param);
   if (!value) {
     return absl::NotFoundError("Not a scalar value inside attributes.");
   }
@@ -391,7 +391,7 @@ absl::Status TryMeanStdDevNormalization(
   Node* first_mean_node = graph.GetNode(first_node_id);
   RETURN_IF_ERROR(CheckIfValidNodeOfType(first_mean_node, OperationType::MEAN));
   auto first_mean_attr =
-      absl::any_cast<MeanAttributes>(first_mean_node->operation.attributes);
+      std::any_cast<MeanAttributes>(first_mean_node->operation.attributes);
   if (first_mean_attr.dims != std::set<Axis>{Axis::CHANNELS}) {
     return absl::NotFoundError("MeanStdDevNormalization not suitable.");
   }
diff --git a/tensorflow/lite/delegates/gpu/common/tasks/prelu.cc b/tensorflow/lite/delegates/gpu/common/tasks/prelu.cc
index 7ad25f78..81b5b7c5 100644
--- a/tensorflow/lite/delegates/gpu/common/tasks/prelu.cc
+++ b/tensorflow/lite/delegates/gpu/common/tasks/prelu.cc
@@ -31,7 +31,7 @@ ElementwiseDescriptor CreatePReLU(const PReLUAttributes& attr,
   ElementwiseDescriptor op_desc;
   std::string alpha_read;
   auto alpha_linear =
-      absl::get_if<tflite::gpu::Tensor<Linear, DataType::FLOAT32>>(&attr.alpha);
+      std::get_if<tflite::gpu::Tensor<Linear, DataType::FLOAT32>>(&attr.alpha);
   if (alpha_linear) {
     TensorDescriptor alpha_tensor_desc = CreateConstantLinearTensorDescriptor(
         tensor_desc.GetDataType(), tensor_desc.GetStorageType(), *alpha_linear);
@@ -41,7 +41,7 @@ ElementwiseDescriptor CreatePReLU(const PReLUAttributes& attr,
   }
 
   auto alpha_hwc =
-      absl::get_if<tflite::gpu::Tensor<HWC, DataType::FLOAT32>>(&attr.alpha);
+      std::get_if<tflite::gpu::Tensor<HWC, DataType::FLOAT32>>(&attr.alpha);
   if (alpha_hwc) {
     const BHWC shape =
         BHWC(1, alpha_hwc->shape.h, alpha_hwc->shape.w, alpha_hwc->shape.c);
diff --git a/tensorflow/lite/delegates/gpu/common/tasks/special/dw7x7_conv2to6_concat_conv8to8.cc b/tensorflow/lite/delegates/gpu/common/tasks/special/dw7x7_conv2to6_concat_conv8to8.cc
index ced3435f..ad8c84d7 100644
--- a/tensorflow/lite/delegates/gpu/common/tasks/special/dw7x7_conv2to6_concat_conv8to8.cc
+++ b/tensorflow/lite/delegates/gpu/common/tasks/special/dw7x7_conv2to6_concat_conv8to8.cc
@@ -183,7 +183,7 @@ GPUOperation CreateDW7x7Conv2To6ConcatConv8to8(
     constants.push_back(conv2to6.weights.data[i]);
   }
 
-  auto alpha0 = absl::get_if<tflite::gpu::Tensor<Linear, DataType::FLOAT32>>(
+  auto alpha0 = std::get_if<tflite::gpu::Tensor<Linear, DataType::FLOAT32>>(
       &prelu0.alpha);
   for (int i = 0; i < 6; ++i) {
     constants.push_back(alpha0->data[i]);
@@ -222,7 +222,7 @@ GPUOperation CreateDW7x7Conv2To6ConcatConv8to8(
     }
   }
 
-  auto alpha1 = absl::get_if<tflite::gpu::Tensor<Linear, DataType::FLOAT32>>(
+  auto alpha1 = std::get_if<tflite::gpu::Tensor<Linear, DataType::FLOAT32>>(
       &prelu1.alpha);
   for (int i = 0; i < 8; ++i) {
     constants.push_back(alpha1->data[i]);
@@ -273,7 +273,7 @@ absl::Status TryDW7x7Conv2To6ConcatConv8to8(
   }
 
   DepthwiseConvolution2DAttributes* dw_attr =
-      absl::any_cast<DepthwiseConvolution2DAttributes>(
+      std::any_cast<DepthwiseConvolution2DAttributes>(
           &dw_node->operation.attributes);
   const bool kGoodDwWeights =
       dw_attr->weights.shape.w == 7 && dw_attr->weights.shape.h == 7 &&
@@ -308,7 +308,8 @@ absl::Status TryDW7x7Conv2To6ConcatConv8to8(
       OperationType::CONVOLUTION_2D) {
     return absl::NotFoundError("DW7x7Conv2To6ConcatConv8to8 not suitable.");
   }
-  Convolution2DAttributes* conv1_attr = absl::any_cast<Convolution2DAttributes>(
+  Convolution2DAttributes* conv1_attr =
+      std::any_cast<Convolution2DAttributes>(
       &conv1_node->operation.attributes);
   if (!IsConv1x1(*conv1_attr) || conv1_attr->weights.shape.i != 2 ||
       conv1_attr->weights.shape.o != 6) {
@@ -370,7 +371,7 @@ absl::Status TryDW7x7Conv2To6ConcatConv8to8(
     return absl::NotFoundError("DW7x7Conv2To6ConcatConv8to8 not suitable.");
   }
   Pooling2DAttributes* pooling_attr =
-      absl::any_cast<Pooling2DAttributes>(&pooling_node->operation.attributes);
+      std::any_cast<Pooling2DAttributes>(&pooling_node->operation.attributes);
   if (pooling_attr->type != PoolingType::MAX || pooling_attr->output_indices ||
       pooling_attr->kernel.w != 2 || pooling_attr->kernel.h != 2 ||
       pooling_attr->strides.w != 2 || pooling_attr->strides.h != 2 ||
@@ -394,7 +395,7 @@ absl::Status TryDW7x7Conv2To6ConcatConv8to8(
       OperationType::CONVOLUTION_2D) {
     return absl::NotFoundError("DW7x7Conv2To6ConcatConv8to8 not suitable.");
   }
-  Convolution2DAttributes* conv2_attr = absl::any_cast<Convolution2DAttributes>(
+  Convolution2DAttributes* conv2_attr = std::any_cast<Convolution2DAttributes>(
       &conv2_node->operation.attributes);
   if (!IsConv1x1(*conv2_attr) || conv2_attr->weights.shape.i != 8 ||
       conv2_attr->weights.shape.o != 8) {
@@ -438,9 +439,9 @@ absl::Status TryDW7x7Conv2To6ConcatConv8to8(
   }
 
   PReLUAttributes* prelu1_attr =
-      absl::any_cast<PReLUAttributes>(&prelu1_node->operation.attributes);
+      std::any_cast<PReLUAttributes>(&prelu1_node->operation.attributes);
   PReLUAttributes* prelu2_attr =
-      absl::any_cast<PReLUAttributes>(&prelu2_node->operation.attributes);
+      std::any_cast<PReLUAttributes>(&prelu2_node->operation.attributes);
 
   std::vector<Value*> op_outputs = {concat_outputs[0], prelu2_outputs[0]};
   std::unique_ptr<GPUOperation>* gpu_op =
diff --git a/tensorflow/lite/delegates/gpu/common/tasks/special/thin_pointwise_fuser.cc b/tensorflow/lite/delegates/gpu/common/tasks/special/thin_pointwise_fuser.cc
index 902ef54a..691beab1 100644
--- a/tensorflow/lite/delegates/gpu/common/tasks/special/thin_pointwise_fuser.cc
+++ b/tensorflow/lite/delegates/gpu/common/tasks/special/thin_pointwise_fuser.cc
@@ -350,7 +350,7 @@ bool ThinPointwiseFuser::IsNodeSupported(const GpuInfo& gpu_info,
       return false;
     }
     DepthwiseConvolution2DAttributes* dw_attr =
-        absl::any_cast<DepthwiseConvolution2DAttributes>(
+        std::any_cast<DepthwiseConvolution2DAttributes>(
             &node->operation.attributes);
     const auto dw_shape = dw_attr->weights.shape;
     bool good_dw = dw_shape.o == 1;
@@ -387,7 +387,7 @@ bool ThinPointwiseFuser::IsNodeSupported(const GpuInfo& gpu_info,
       return false;
     }
     Convolution2DAttributes* conv_attr =
-        absl::any_cast<Convolution2DAttributes>(&node->operation.attributes);
+        std::any_cast<Convolution2DAttributes>(&node->operation.attributes);
     if (conv_attr->groups != 1) {
       return false;
     }
@@ -462,12 +462,12 @@ bool ThinPointwiseFuser::ReserveNode(const GpuInfo& gpu_info, Node* node) {
   if (IsConvNode(node)) {
     convs_count_++;
     Convolution2DAttributes* conv_attr =
-        absl::any_cast<Convolution2DAttributes>(&node->operation.attributes);
+        std::any_cast<Convolution2DAttributes>(&node->operation.attributes);
     buffer_size_ += GetConvWeightsSize(*conv_attr, op_def_.precision);
   }
   if (IsDwConvNode(node)) {
     DepthwiseConvolution2DAttributes* dw_attr =
-        absl::any_cast<DepthwiseConvolution2DAttributes>(
+        std::any_cast<DepthwiseConvolution2DAttributes>(
             &node->operation.attributes);
     buffer_size_ += GetDepthwiseConvWeightsSize(*dw_attr, op_def_.precision);
   }
@@ -479,12 +479,12 @@ uint64_t ThinPointwiseFuser::GetNodeFlops(Node* node) const {
   auto output_shape = graph_->FindOutputs(node->id)[0]->tensor.shape;
   if (op_type == OperationType::DEPTHWISE_CONVOLUTION) {
     DepthwiseConvolution2DAttributes* attr =
-        absl::any_cast<DepthwiseConvolution2DAttributes>(
+        std::any_cast<DepthwiseConvolution2DAttributes>(
             &node->operation.attributes);
     return GetDepthwiseConvolutionFlops(output_shape, attr->weights.shape);
   } else if (op_type == OperationType::CONVOLUTION_2D) {
     Convolution2DAttributes* attr =
-        absl::any_cast<Convolution2DAttributes>(&node->operation.attributes);
+        std::any_cast<Convolution2DAttributes>(&node->operation.attributes);
     return GetConvolutionFlops(output_shape, attr->weights.shape);
   }
   return 0;
@@ -495,11 +495,11 @@ void ThinPointwiseFuser::AddNode(const GpuInfo& gpu_info, int node_index) {
   auto op_type = OperationTypeFromString(node->operation.type);
   if (op_type == OperationType::RELU) {
     ReLUAttributes* attr =
-        absl::any_cast<ReLUAttributes>(&node->operation.attributes);
+        std::any_cast<ReLUAttributes>(&node->operation.attributes);
     AddReluNode(*attr);
   } else if (op_type == OperationType::PRELU) {
     PReLUAttributes* attr =
-        absl::any_cast<PReLUAttributes>(&node->operation.attributes);
+        std::any_cast<PReLUAttributes>(&node->operation.attributes);
     AddPreluNode(*attr);
   } else if (op_type == OperationType::ADD) {
     Node* prev_node = nodes_[node_index - 1];
@@ -514,12 +514,12 @@ void ThinPointwiseFuser::AddNode(const GpuInfo& gpu_info, int node_index) {
     AddElementwiseOneInputNode(gpu_info, op_type);
   } else if (op_type == OperationType::DEPTHWISE_CONVOLUTION) {
     DepthwiseConvolution2DAttributes* attr =
-        absl::any_cast<DepthwiseConvolution2DAttributes>(
+        std::any_cast<DepthwiseConvolution2DAttributes>(
             &node->operation.attributes);
     AddDepthwiseConvNode(gpu_info, *attr);
   } else if (op_type == OperationType::CONVOLUTION_2D) {
     Convolution2DAttributes* attr =
-        absl::any_cast<Convolution2DAttributes>(&node->operation.attributes);
+        std::any_cast<Convolution2DAttributes>(&node->operation.attributes);
     if (IsConv1x1(*attr) && node_index != 0) {
       AddConv1x1Node(gpu_info, *attr, node_index == nodes_.size() - 1);
     } else {
diff --git a/tensorflow/lite/delegates/gpu/common/transformations/add_bias.cc b/tensorflow/lite/delegates/gpu/common/transformations/add_bias.cc
index ae3e4e54..d8ceeec7 100644
--- a/tensorflow/lite/delegates/gpu/common/transformations/add_bias.cc
+++ b/tensorflow/lite/delegates/gpu/common/transformations/add_bias.cc
@@ -59,12 +59,12 @@ class AddBias : public NodeTransformation {
                 "runtime input."};
       }
       auto& attr =
-          absl::any_cast<Convolution2DAttributes&>(node->operation.attributes);
+          std::any_cast<Convolution2DAttributes&>(node->operation.attributes);
       return FillBias(attr.weights.shape.o, &attr.bias);
     }
     if (node->operation.type ==
         ToString(OperationType::CONVOLUTION_TRANSPOSED)) {
-      auto& attr = absl::any_cast<ConvolutionTransposedAttributes&>(
+      auto& attr = std::any_cast<ConvolutionTransposedAttributes&>(
           node->operation.attributes);
       return FillBias(attr.weights.shape.o, &attr.bias);
     }
@@ -76,17 +76,17 @@ class AddBias : public NodeTransformation {
                 "with one "
                 "runtime input."};
       }
-      auto& attr = absl::any_cast<DepthwiseConvolution2DAttributes&>(
+      auto& attr = std::any_cast<DepthwiseConvolution2DAttributes&>(
           node->operation.attributes);
       return FillBias(attr.weights.shape.o * attr.weights.shape.i, &attr.bias);
     }
     if (node->operation.type == ToString(OperationType::FULLY_CONNECTED)) {
       auto& attr =
-          absl::any_cast<FullyConnectedAttributes&>(node->operation.attributes);
+          std::any_cast<FullyConnectedAttributes&>(node->operation.attributes);
       return FillBias(attr.weights.shape.o, &attr.bias);
     }
     if (node->operation.type == ToString(OperationType::FULLY_CONNECTED_INT8)) {
-      auto& attr = absl::any_cast<FullyConnectedInt8Attributes&>(
+      auto& attr = std::any_cast<FullyConnectedInt8Attributes&>(
           node->operation.attributes);
       return FillBias(attr.weights.shape.o, &attr.bias);
     }
diff --git a/tensorflow/lite/delegates/gpu/common/transformations/fuse_add_to_conv.cc b/tensorflow/lite/delegates/gpu/common/transformations/fuse_add_to_conv.cc
index 673502f2..3b386d80 100644
--- a/tensorflow/lite/delegates/gpu/common/transformations/fuse_add_to_conv.cc
+++ b/tensorflow/lite/delegates/gpu/common/transformations/fuse_add_to_conv.cc
@@ -37,8 +37,8 @@ namespace {
 void FuseBiasWithAddAttributes(const ElementwiseAttributes& add_attr,
                                const int channels,
                                Tensor<Linear, DataType::FLOAT32>* bias) {
-  auto add = absl::get_if<Tensor<Linear, DataType::FLOAT32>>(&add_attr.param);
-  auto add_scalar = absl::get_if<float>(&add_attr.param);
+  auto add = std::get_if<Tensor<Linear, DataType::FLOAT32>>(&add_attr.param);
+  auto add_scalar = std::get_if<float>(&add_attr.param);
   if (bias->data.empty()) {
     *bias = MakeZeroTensor<Linear, DataType::FLOAT32>(Linear(channels));
   }
@@ -63,35 +63,35 @@ class MergeConvolutionWithAdd : public SequenceTransformation {
       return {TransformStatus::SKIPPED, ""};
     }
     ElementwiseAttributes add_attr =
-        absl::any_cast<ElementwiseAttributes>(add_node.operation.attributes);
-    if (!absl::holds_alternative<Tensor<Linear, DataType::FLOAT32>>(
+        std::any_cast<ElementwiseAttributes>(add_node.operation.attributes);
+    if (!std::holds_alternative<Tensor<Linear, DataType::FLOAT32>>(
             add_attr.param) &&
-        !absl::holds_alternative<float>(add_attr.param)) {
+        !std::holds_alternative<float>(add_attr.param)) {
       return {TransformStatus::DECLINED,
               "This fuse applicable only for broadcast or scalar addition."};
     }
 
     if (conv_node.operation.type == ToString(OperationType::CONVOLUTION_2D)) {
       Convolution2DAttributes* conv_attr =
-          absl::any_cast<Convolution2DAttributes>(
+          std::any_cast<Convolution2DAttributes>(
               &conv_node.operation.attributes);
       FuseConvolution2DWithAdd(add_attr, conv_attr);
     } else if (conv_node.operation.type ==
                ToString(OperationType::CONVOLUTION_TRANSPOSED)) {
       ConvolutionTransposedAttributes* conv_attr =
-          absl::any_cast<ConvolutionTransposedAttributes>(
+          std::any_cast<ConvolutionTransposedAttributes>(
               &conv_node.operation.attributes);
       FuseConvolutionTransposedWithAdd(add_attr, conv_attr);
     } else if (conv_node.operation.type ==
                ToString(OperationType::DEPTHWISE_CONVOLUTION)) {
       DepthwiseConvolution2DAttributes* conv_attr =
-          absl::any_cast<DepthwiseConvolution2DAttributes>(
+          std::any_cast<DepthwiseConvolution2DAttributes>(
               &conv_node.operation.attributes);
       FuseDepthwiseConvolution2DWithAdd(add_attr, conv_attr);
     } else if (conv_node.operation.type ==
                ToString(OperationType::FULLY_CONNECTED)) {
       FullyConnectedAttributes* conv_attr =
-          absl::any_cast<FullyConnectedAttributes>(
+          std::any_cast<FullyConnectedAttributes>(
               &conv_node.operation.attributes);
       FuseFullyConnectedWithAdd(add_attr, conv_attr);
     } else {
@@ -110,8 +110,8 @@ class MergeConvolutionWithAdd : public SequenceTransformation {
 
 void FuseAddWithConvolution2D(const ElementwiseAttributes& add_attr,
                               Convolution2DAttributes* attr) {
-  auto add = absl::get_if<Tensor<Linear, DataType::FLOAT32>>(&add_attr.param);
-  auto add_scalar = absl::get_if<float>(&add_attr.param);
+  auto add = std::get_if<Tensor<Linear, DataType::FLOAT32>>(&add_attr.param);
+  auto add_scalar = std::get_if<float>(&add_attr.param);
   if (attr->bias.data.empty()) {
     attr->bias = MakeZeroTensor<Linear, DataType::FLOAT32>(
         Linear(attr->weights.shape.o));
@@ -147,17 +147,17 @@ class MergeAddWithConvolution : public SequenceTransformation {
       return {TransformStatus::SKIPPED, ""};
     }
     ElementwiseAttributes add_attr =
-        absl::any_cast<ElementwiseAttributes>(add_node.operation.attributes);
-    if (!absl::holds_alternative<Tensor<Linear, DataType::FLOAT32>>(
+        std::any_cast<ElementwiseAttributes>(add_node.operation.attributes);
+    if (!std::holds_alternative<Tensor<Linear, DataType::FLOAT32>>(
             add_attr.param) &&
-        !absl::holds_alternative<float>(add_attr.param)) {
+        !std::holds_alternative<float>(add_attr.param)) {
       return {TransformStatus::DECLINED,
               "This fuse applicable only for broadcast or scalar addition."};
     }
 
     if (conv_node.operation.type == ToString(OperationType::CONVOLUTION_2D)) {
       Convolution2DAttributes* conv_attr =
-          absl::any_cast<Convolution2DAttributes>(
+          std::any_cast<Convolution2DAttributes>(
               &conv_node.operation.attributes);
       if (conv_attr->groups != 1) {
         return {TransformStatus::DECLINED,
diff --git a/tensorflow/lite/delegates/gpu/common/transformations/fuse_mul_to_conv.cc b/tensorflow/lite/delegates/gpu/common/transformations/fuse_mul_to_conv.cc
index 41bd485a..98523a3a 100644
--- a/tensorflow/lite/delegates/gpu/common/transformations/fuse_mul_to_conv.cc
+++ b/tensorflow/lite/delegates/gpu/common/transformations/fuse_mul_to_conv.cc
@@ -53,10 +53,10 @@ class MergeConvolutionWithMul : public SequenceTransformation {
     }
 
     ElementwiseAttributes mul_attr =
-        absl::any_cast<ElementwiseAttributes>(mul_node.operation.attributes);
-    if (!absl::holds_alternative<Tensor<Linear, DataType::FLOAT32>>(
+        std::any_cast<ElementwiseAttributes>(mul_node.operation.attributes);
+    if (!std::holds_alternative<Tensor<Linear, DataType::FLOAT32>>(
             mul_attr.param) &&
-        !absl::holds_alternative<float>(mul_attr.param)) {
+        !std::holds_alternative<float>(mul_attr.param)) {
       return {
           TransformStatus::DECLINED,
           "This fuse applicable only for broadcast or scalar multiplication."};
@@ -64,25 +64,25 @@ class MergeConvolutionWithMul : public SequenceTransformation {
 
     if (conv_node.operation.type == ToString(OperationType::CONVOLUTION_2D)) {
       Convolution2DAttributes* conv_attr =
-          absl::any_cast<Convolution2DAttributes>(
+          std::any_cast<Convolution2DAttributes>(
               &conv_node.operation.attributes);
       FuseConvolution2DWithMultiply(mul_attr, conv_attr);
     } else if (conv_node.operation.type ==
                ToString(OperationType::CONVOLUTION_TRANSPOSED)) {
       ConvolutionTransposedAttributes* conv_attr =
-          absl::any_cast<ConvolutionTransposedAttributes>(
+          std::any_cast<ConvolutionTransposedAttributes>(
               &conv_node.operation.attributes);
       FuseConvolutionTransposedWithMultiply(mul_attr, conv_attr);
     } else if (conv_node.operation.type ==
                ToString(OperationType::DEPTHWISE_CONVOLUTION)) {
       DepthwiseConvolution2DAttributes* conv_attr =
-          absl::any_cast<DepthwiseConvolution2DAttributes>(
+          std::any_cast<DepthwiseConvolution2DAttributes>(
               &conv_node.operation.attributes);
       FuseDepthwiseConvolution2DWithMultiply(mul_attr, conv_attr);
     } else if (conv_node.operation.type ==
                ToString(OperationType::FULLY_CONNECTED)) {
       FullyConnectedAttributes* conv_attr =
-          absl::any_cast<FullyConnectedAttributes>(
+          std::any_cast<FullyConnectedAttributes>(
               &conv_node.operation.attributes);
       FuseFullyConnectedWithMultiply(mul_attr, conv_attr);
     } else {
@@ -117,10 +117,10 @@ class MergeMulWithConvolution : public SequenceTransformation {
     }
 
     ElementwiseAttributes mul_attr =
-        absl::any_cast<ElementwiseAttributes>(mul_node.operation.attributes);
-    if (!absl::holds_alternative<Tensor<Linear, DataType::FLOAT32>>(
+        std::any_cast<ElementwiseAttributes>(mul_node.operation.attributes);
+    if (!std::holds_alternative<Tensor<Linear, DataType::FLOAT32>>(
             mul_attr.param) &&
-        !absl::holds_alternative<float>(mul_attr.param)) {
+        !std::holds_alternative<float>(mul_attr.param)) {
       return {
           TransformStatus::DECLINED,
           "This fuse applicable only for broadcast or scalar multiplication."};
@@ -128,25 +128,25 @@ class MergeMulWithConvolution : public SequenceTransformation {
 
     if (conv_node.operation.type == ToString(OperationType::CONVOLUTION_2D)) {
       Convolution2DAttributes* conv_attr =
-          absl::any_cast<Convolution2DAttributes>(
+          std::any_cast<Convolution2DAttributes>(
               &conv_node.operation.attributes);
       FuseMultiplyWithConvolution2D(mul_attr, conv_attr);
     } else if (conv_node.operation.type ==
                ToString(OperationType::CONVOLUTION_TRANSPOSED)) {
       ConvolutionTransposedAttributes* conv_attr =
-          absl::any_cast<ConvolutionTransposedAttributes>(
+          std::any_cast<ConvolutionTransposedAttributes>(
               &conv_node.operation.attributes);
       FuseMultiplyWithConvolutionTransposed(mul_attr, conv_attr);
     } else if (conv_node.operation.type ==
                ToString(OperationType::DEPTHWISE_CONVOLUTION)) {
       DepthwiseConvolution2DAttributes* conv_attr =
-          absl::any_cast<DepthwiseConvolution2DAttributes>(
+          std::any_cast<DepthwiseConvolution2DAttributes>(
               &conv_node.operation.attributes);
       FuseMultiplyWithDepthwiseConvolution2D(mul_attr, conv_attr);
     } else if (conv_node.operation.type ==
                ToString(OperationType::FULLY_CONNECTED)) {
       FullyConnectedAttributes* conv_attr =
-          absl::any_cast<FullyConnectedAttributes>(
+          std::any_cast<FullyConnectedAttributes>(
               &conv_node.operation.attributes);
       FuseMultiplyWithFullyConnected(mul_attr, conv_attr);
     } else {
@@ -175,8 +175,8 @@ std::unique_ptr<SequenceTransformation> NewMergeMulWithConvolution() {
 
 void FuseConvolution2DWithMultiply(const ElementwiseAttributes& mul_attr,
                                    Convolution2DAttributes* attr) {
-  auto mul = absl::get_if<Tensor<Linear, DataType::FLOAT32>>(&mul_attr.param);
-  auto mul_scalar = absl::get_if<float>(&mul_attr.param);
+  auto mul = std::get_if<Tensor<Linear, DataType::FLOAT32>>(&mul_attr.param);
+  auto mul_scalar = std::get_if<float>(&mul_attr.param);
   for (int d = 0; d < attr->weights.shape.o; ++d) {
     const float multiplier = mul ? mul->data[d] : *mul_scalar;
     for (int s = 0; s < attr->weights.shape.i; ++s) {
@@ -196,8 +196,8 @@ void FuseConvolution2DWithMultiply(const ElementwiseAttributes& mul_attr,
 void FuseDepthwiseConvolution2DWithMultiply(
     const ElementwiseAttributes& mul_attr,
     DepthwiseConvolution2DAttributes* attr) {
-  auto mul = absl::get_if<Tensor<Linear, DataType::FLOAT32>>(&mul_attr.param);
-  auto mul_scalar = absl::get_if<float>(&mul_attr.param);
+  auto mul = std::get_if<Tensor<Linear, DataType::FLOAT32>>(&mul_attr.param);
+  auto mul_scalar = std::get_if<float>(&mul_attr.param);
   for (int g = 0; g < attr->weights.shape.o; ++g) {
     for (int s = 0; s < attr->weights.shape.i; ++s) {
       const int d = s * attr->weights.shape.o + g;
@@ -218,8 +218,8 @@ void FuseDepthwiseConvolution2DWithMultiply(
 void FuseConvolutionTransposedWithMultiply(
     const ElementwiseAttributes& mul_attr,
     ConvolutionTransposedAttributes* attr) {
-  auto mul = absl::get_if<Tensor<Linear, DataType::FLOAT32>>(&mul_attr.param);
-  auto mul_scalar = absl::get_if<float>(&mul_attr.param);
+  auto mul = std::get_if<Tensor<Linear, DataType::FLOAT32>>(&mul_attr.param);
+  auto mul_scalar = std::get_if<float>(&mul_attr.param);
   for (int d = 0; d < attr->weights.shape.o; ++d) {
     const float multiplier = mul ? mul->data[d] : *mul_scalar;
     for (int s = 0; s < attr->weights.shape.i; ++s) {
@@ -238,8 +238,8 @@ void FuseConvolutionTransposedWithMultiply(
 
 void FuseFullyConnectedWithMultiply(const ElementwiseAttributes& mul_attr,
                                     FullyConnectedAttributes* attr) {
-  auto mul = absl::get_if<Tensor<Linear, DataType::FLOAT32>>(&mul_attr.param);
-  auto mul_scalar = absl::get_if<float>(&mul_attr.param);
+  auto mul = std::get_if<Tensor<Linear, DataType::FLOAT32>>(&mul_attr.param);
+  auto mul_scalar = std::get_if<float>(&mul_attr.param);
   for (int d = 0; d < attr->weights.shape.o; ++d) {
     const float multiplier = mul ? mul->data[d] : *mul_scalar;
     for (int s = 0; s < attr->weights.shape.i; ++s) {
@@ -254,8 +254,8 @@ void FuseFullyConnectedWithMultiply(const ElementwiseAttributes& mul_attr,
 
 void FuseMultiplyWithConvolution2D(const ElementwiseAttributes& mul_attr,
                                    Convolution2DAttributes* attr) {
-  auto mul = absl::get_if<Tensor<Linear, DataType::FLOAT32>>(&mul_attr.param);
-  auto mul_scalar = absl::get_if<float>(&mul_attr.param);
+  auto mul = std::get_if<Tensor<Linear, DataType::FLOAT32>>(&mul_attr.param);
+  auto mul_scalar = std::get_if<float>(&mul_attr.param);
   for (int s = 0; s < attr->weights.shape.i; ++s) {
     const float multiplier = mul ? mul->data[s] : *mul_scalar;
     for (int d = 0; d < attr->weights.shape.o; ++d) {
@@ -272,8 +272,8 @@ void FuseMultiplyWithConvolution2D(const ElementwiseAttributes& mul_attr,
 void FuseMultiplyWithDepthwiseConvolution2D(
     const ElementwiseAttributes& mul_attr,
     DepthwiseConvolution2DAttributes* attr) {
-  auto mul = absl::get_if<Tensor<Linear, DataType::FLOAT32>>(&mul_attr.param);
-  auto mul_scalar = absl::get_if<float>(&mul_attr.param);
+  auto mul = std::get_if<Tensor<Linear, DataType::FLOAT32>>(&mul_attr.param);
+  auto mul_scalar = std::get_if<float>(&mul_attr.param);
   for (int s = 0; s < attr->weights.shape.i; ++s) {
     const float multiplier = mul ? mul->data[s] : *mul_scalar;
     for (int g = 0; g < attr->weights.shape.o; ++g) {
@@ -290,8 +290,8 @@ void FuseMultiplyWithDepthwiseConvolution2D(
 void FuseMultiplyWithConvolutionTransposed(
     const ElementwiseAttributes& mul_attr,
     ConvolutionTransposedAttributes* attr) {
-  auto mul = absl::get_if<Tensor<Linear, DataType::FLOAT32>>(&mul_attr.param);
-  auto mul_scalar = absl::get_if<float>(&mul_attr.param);
+  auto mul = std::get_if<Tensor<Linear, DataType::FLOAT32>>(&mul_attr.param);
+  auto mul_scalar = std::get_if<float>(&mul_attr.param);
   for (int s = 0; s < attr->weights.shape.i; ++s) {
     const float multiplier = mul ? mul->data[s] : *mul_scalar;
     for (int d = 0; d < attr->weights.shape.o; ++d) {
@@ -307,8 +307,8 @@ void FuseMultiplyWithConvolutionTransposed(
 
 void FuseMultiplyWithFullyConnected(const ElementwiseAttributes& mul_attr,
                                     FullyConnectedAttributes* attr) {
-  auto mul = absl::get_if<Tensor<Linear, DataType::FLOAT32>>(&mul_attr.param);
-  auto mul_scalar = absl::get_if<float>(&mul_attr.param);
+  auto mul = std::get_if<Tensor<Linear, DataType::FLOAT32>>(&mul_attr.param);
+  auto mul_scalar = std::get_if<float>(&mul_attr.param);
   for (int s = 0; s < attr->weights.shape.i; ++s) {
     const float multiplier = mul ? mul->data[s] : *mul_scalar;
     for (int d = 0; d < attr->weights.shape.o; ++d) {
diff --git a/tensorflow/lite/delegates/gpu/common/transformations/merge_densify.cc b/tensorflow/lite/delegates/gpu/common/transformations/merge_densify.cc
index 4befb35d..2fc09ef6 100644
--- a/tensorflow/lite/delegates/gpu/common/transformations/merge_densify.cc
+++ b/tensorflow/lite/delegates/gpu/common/transformations/merge_densify.cc
@@ -71,7 +71,7 @@ class MergeDensify : public NodeTransformation {
 
     // Create a copy of the const tensor with a cast from BHWC to OHWI.
     const Tensor<BHWC, DataType::FLOAT32>& src =
-        absl::any_cast<DensifyAttributes>(&densify_node->operation.attributes)
+        std::any_cast<DensifyAttributes>(&densify_node->operation.attributes)
             ->tensor;
     Tensor<OHWI, DataType::FLOAT32> dst;
     dst.id = src.id;
@@ -90,10 +90,10 @@ class MergeDensify : public NodeTransformation {
 
     // Update CONV_2D / DEPTHWISE_CONV_2D weights.
     if (node->operation.type == ToString(OperationType::CONVOLUTION_2D)) {
-      absl::any_cast<Convolution2DAttributes>(&node->operation.attributes)
+      std::any_cast<Convolution2DAttributes>(&node->operation.attributes)
           ->weights = std::move(dst);
     } else {
-      absl::any_cast<DepthwiseConvolution2DAttributes>(
+      std::any_cast<DepthwiseConvolution2DAttributes>(
           &node->operation.attributes)
           ->weights = std::move(dst);
     }
diff --git a/tensorflow/lite/delegates/gpu/common/transformations/merge_padding_with.cc b/tensorflow/lite/delegates/gpu/common/transformations/merge_padding_with.cc
index 509d715f..8a6f47ba 100644
--- a/tensorflow/lite/delegates/gpu/common/transformations/merge_padding_with.cc
+++ b/tensorflow/lite/delegates/gpu/common/transformations/merge_padding_with.cc
@@ -56,7 +56,7 @@ class MergePaddingWith2DOperation : public SequenceTransformation {
     Node* op_node = sequence.back();
 
     PadAttributes pad_attr =
-        absl::any_cast<PadAttributes>(pad_node->operation.attributes);
+        std::any_cast<PadAttributes>(pad_node->operation.attributes);
 
     if (pad_attr.type != PaddingContentType::ZEROS) {
       return {TransformStatus::DECLINED, "Only Zero padding is supported."};
@@ -67,7 +67,7 @@ class MergePaddingWith2DOperation : public SequenceTransformation {
               "Pad has non-zero padding on non HW axis."};
     }
 
-    Attr* node_attr = absl::any_cast<Attr>(&op_node->operation.attributes);
+    Attr* node_attr = std::any_cast<Attr>(&op_node->operation.attributes);
     absl::Status status = RemovePrecedingNode(graph, pad_node, op_node);
     if (!status.ok()) {
       return {TransformStatus::INVALID,
@@ -128,7 +128,7 @@ class MergePaddingWithAddOperation : public NodeTransformation {
     }
 
     PadAttributes pad_attr =
-        absl::any_cast<PadAttributes>(node->operation.attributes);
+        std::any_cast<PadAttributes>(node->operation.attributes);
 
     if (pad_attr.type != PaddingContentType::ZEROS) {
       return {TransformStatus::DECLINED, "Only Zero padding is supported."};
@@ -151,13 +151,13 @@ class MergePaddingWithAddOperation : public NodeTransformation {
     }
 
     ElementwiseAttributes add_attr =
-        absl::any_cast<ElementwiseAttributes>(add_node->operation.attributes);
+        std::any_cast<ElementwiseAttributes>(add_node->operation.attributes);
     const bool is_add_hwc =
-        absl::holds_alternative<Tensor<HWC, DataType::FLOAT32>>(add_attr.param);
+        std::holds_alternative<Tensor<HWC, DataType::FLOAT32>>(add_attr.param);
     const bool is_add_linear =
-        absl::holds_alternative<Tensor<Linear, DataType::FLOAT32>>(
+        std::holds_alternative<Tensor<Linear, DataType::FLOAT32>>(
             add_attr.param);
-    const bool is_add_scalar = absl::holds_alternative<float>(add_attr.param);
+    const bool is_add_scalar = std::holds_alternative<float>(add_attr.param);
     if (is_add_hwc || is_add_linear || is_add_scalar) {
       return {TransformStatus::SKIPPED,
               "Cannot remove padding when ADD has constant argument."};
diff --git a/tensorflow/lite/delegates/gpu/common/transformations/remove_noop.cc b/tensorflow/lite/delegates/gpu/common/transformations/remove_noop.cc
index ceb66dd5..30366f8b 100644
--- a/tensorflow/lite/delegates/gpu/common/transformations/remove_noop.cc
+++ b/tensorflow/lite/delegates/gpu/common/transformations/remove_noop.cc
@@ -86,13 +86,13 @@ std::unique_ptr<SequenceTransformation> NewRemoveSingleInputAdd() {
         if (node->operation.type != type) {
           return false;
         }
-        auto& attr = absl::any_cast<const ElementwiseAttributes&>(
+        auto& attr = std::any_cast<const ElementwiseAttributes&>(
             node->operation.attributes);
-        return !absl::holds_alternative<Tensor<HWC, DataType::FLOAT32>>(
+        return !std::holds_alternative<Tensor<HWC, DataType::FLOAT32>>(
                    attr.param) &&
-               !absl::holds_alternative<Tensor<Linear, DataType::FLOAT32>>(
+               !std::holds_alternative<Tensor<Linear, DataType::FLOAT32>>(
                    attr.param) &&
-               !absl::holds_alternative<float>(attr.param);
+               !std::holds_alternative<float>(attr.param);
       });
 }
 
@@ -118,7 +118,7 @@ class RemoveIdentityReshape : public NodeTransformation {
     }
     auto input_shape = graph->FindInputs(node->id)[0]->tensor.shape;
     const auto& reshape_attr =
-        absl::any_cast<const ReshapeAttributes&>(node->operation.attributes);
+        std::any_cast<const ReshapeAttributes&>(node->operation.attributes);
     if (input_shape != reshape_attr.new_shape) {
       return {TransformStatus::SKIPPED, ""};
     }
@@ -152,7 +152,7 @@ class RemoveIdentityStridedSlice : public NodeTransformation {
     auto input = graph->FindInputs(node->id)[0];
     auto output = graph->FindOutputs(node->id)[0];
     const auto& slice_attr =
-        absl::any_cast<const SliceAttributes&>(node->operation.attributes);
+        std::any_cast<const SliceAttributes&>(node->operation.attributes);
     if (input->tensor.shape != output->tensor.shape) {
       return {TransformStatus::SKIPPED, ""};
     }
