{
  "name": "onnxruntime",
  "version-semver": "1.9.1",
  "port-version": 1,
  "description": "ONNX Runtime: cross-platform, high performance ML inferencing and training accelerator",
  "homepage": "www.onnxruntime.ai",
  "supports": "(windows & !static) | linux | osx",
  "dependencies": [
    "boost-config",
    "boost-mp11",
    "cpuinfo",
    "cxxopts",
    "date",
    "eigen3",
    "flatbuffers",
    "nlohmann-json",
    "nsync",
    {
      "name": "nsync",
      "platform": "linux"
    },
    "onnx",
    "optional-lite",
    "protobuf",
    "re2",
    "safeint",
    {
      "name": "vcpkg-cmake",
      "host": true
    },
    {
      "name": "wil",
      "platform": "windows"
    },
    "zlib"
  ],
  "features": {
    "cuda": {
      "description": "Build with CUDA/NCCL support"
    },
    "tensrorrt": {
      "description": "Build with NVIDIA TensorRT support"
    },
    "training": {
      "description": "Turn on build options for ML training"
    }
  }
}
